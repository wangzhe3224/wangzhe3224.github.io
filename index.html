<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Titillium Web:300,300italic,400,400italic,700,700italic|Encode Sans:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null,"activeClass":"disqus"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Things are correlated">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhe">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Zhe">
<meta property="og:description" content="Things are correlated">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhe</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66629043-1"></script>
    <script pjax>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-66629043-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhe</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Unstable Correlation</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-arts">

    <a href="/arts/" rel="section"><i class="fa fa-fw fa-microchip"></i>Arts</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/03/efficiently_inefficient/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/03/efficiently_inefficient/" class="post-title-link" itemprop="url">Efficiently Inefficient Market</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-03 00:00:00" itemprop="dateCreated datePublished" datetime="2020-10-03T00:00:00Z">2020-10-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reading/" itemprop="url" rel="index"><span itemprop="name">Reading</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/10/03/efficiently_inefficient/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/10/03/efficiently_inefficient/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Efficiently-Inefficient-Market"><a href="#Efficiently-Inefficient-Market" class="headerlink" title="Efficiently Inefficient Market"></a>Efficiently Inefficient Market</h1><h1 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h1><p>作者认为，市场足够的有效，但是不是完全有效，也正式基金经理的主动挖掘无效性，才进一步促进了市场的有效。只不过，主动投资是有花销的，比如人力、技能、电脑、场地等等，这些都会为主动管理资金设立门槛，导致超过容量有限。</p>
<p>作者在AQR从事量化投资相关研究，具有很好的学术和工业背景，所以他的见解更加贴合真是市场，但是又包含严谨的说明，没有任何玄学。比如，他就明确的说出：想要盈利就必须要预测，而且要做好的预测。</p>
<p>这一点我很认同，母我看到太多所谓的“交易”达人胡扯：不预测，只是跟随市场。&lt;—- <strong>扯淡</strong>。</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><ul>
<li>价值</li>
<li>趋势</li>
<li>流动性</li>
<li>Carry</li>
<li>质量</li>
</ul>
<h1 id="1、主动投资活动"><a href="#1、主动投资活动" class="headerlink" title="1、主动投资活动"></a>1、主动投资活动</h1><h2 id="评价策略表现"><a href="#评价策略表现" class="headerlink" title="评价策略表现"></a>评价策略表现</h2><p>Alpha, t-statics, sharpe ratio, information ratio, alpha-to-margin ratio, sortino ratio</p>
<h2 id="寻找、回测策略"><a href="#寻找、回测策略" class="headerlink" title="寻找、回测策略"></a>寻找、回测策略</h2><p>每一个策略背后都应该有合理的盈利逻辑，因为你的每一笔交易都会存在对手方，如果你的策略真的有效，那么对手会亏损，问题在于他有什么理由一直亏损？</p>
<p>所以超额利润，alpha，一般来源有两个：流动性的补偿和信息的补偿。</p>
<p><img data-src="https://i.imgur.com/FRHkc6g.png" alt="Alpha的来源"></p>
<p><strong>信息</strong></p>
<p>市场价格如果可以反映该产品的一切信息，那么这个过程不是自动完成的，也不是瞬间完成的，需要有人去交易这些信息，把这些信息反映到市场价格中去。反过来说，如果市场自动、瞬间反映了所有信息，那么不会有人去收集并交易任何信息，因为没有意义。可以，如果是这样的话，市场优又如何可以反映新出现的信息？所以，对冲基金等主动管理者就通过收集和交易信息成全了市场的有效性。</p>
<p>对冲基金往往也充当了信息的生产者，比如他们会对公司进行深入系统的研究，然后做出对应的交易，从而将这些信息反映到价格中。对冲基金也会高价购买信息，然后通过交易行为，将这些信息反映到价格中，并且从中盈利。同时，对冲基金也会交易一些非理性行为，比如</p>
<blockquote>
<p>there is a general tendency of initial underreaction and delayed overreaction that creates trends and momentum.</p>
</blockquote>
<p>所以，当一个新的策略形成的时候，问问自己受益从何而来？</p>
<ul>
<li>这些信息被大部分人忽略了吗？</li>
<li>通过整个多种不同的信息，得到了新的信息吗？</li>
<li>我比其他人更快的获得了这个信息吗？</li>
<li>这些信息还没有完全反映到市场价格吗？</li>
</ul>
<p><strong>风险</strong></p>
<p>获得超额回报的另一个途径就是承担风险。市场风险不计入。通常对冲基金会通过承担流动性风险获得市场收益意外的超额回报。</p>
<p>流动性风险会直接影响资产的价格。</p>
<p><em>市场流动性风险</em>，是指需要花费巨额的费用才能退出某个资产。最常见的情况就是在崩盘的情况下，bid-ask差价非常大，甚至出现没有bid的情况，无人接盘。因此，流动性差的资产通常具有较高的回报率或者比较便宜，这就是市场流动性风险补偿。</p>
<p><em>资本流动性风险</em>，是指被margin call的风险。换句话说，持有高Margin的资产应该得到相应的回报，因为承担了资本流动性风险。</p>
<p><em>需求压力</em>，Demand pressure，并购套利就是一个典型的需求压力策略。当一些机构进行风险对冲的时候，也会出现需求压力。在比如需要roll future contract的时候，债券降级的时候，都会产生一些需求压力，通常都是卖出压力。</p>
<p><strong>回测</strong></p>
<p>回测的基本组成部分：</p>
<ul>
<li>交易池，定义可以交易的资产</li>
<li>信号，信息输入</li>
<li>交易规则，包括调仓规则，交易规则等等</li>
<li>时间延迟，Point-in-time 信息</li>
<li>交易费用</li>
</ul>
<h2 id="回归分析的等效性"><a href="#回归分析的等效性" class="headerlink" title="回归分析的等效性"></a>回归分析的等效性</h2><p>投资组合资产的选择和比较几乎等效于线性回归系数的分析：</p>
<blockquote>
<p>任何预测性质的回归分析都可以等效成资产组合选择，任何资产组合选择都可以等效成为预测回归分析。</p>
</blockquote>
<ul>
<li>时间序列回归分析，与择时策略相关</li>
<li>Corss-sectional回归分析与则产选择策略相关</li>
<li>单因子回归分析与根据一个信号排序资产相关；而多因子回归则与多因子排序相关</li>
</ul>
<h3 id="时间序列回归"><a href="#时间序列回归" class="headerlink" title="时间序列回归"></a>时间序列回归</h3><p>$$R_{t+1}^e = a + bF_t + e_{t+1}$$</p>
<p><strong>而 $b$ 的最小二乘估计值就可以被看成一个long-short择时策略的累计回报率</strong>：</p>
<p>$$\hat{b}=\frac{\sum_t(F_t - \bar{F})R_{t+1}}{\sum_t(F_t-\bar{F})^2} = \sum_{t=1}^{T}x_tR_{t+1}$$</p>
<p>其中，$x_t = k(F_t - \bar{F})$，而$k = 1/\sum(F_t-\bar{F})^2$ 不影响策略的夏普值。</p>
<p>$x_t$就是实际的交易仓位，当信号$F_t$超过其均值时，x为正，即买入。反之，则卖出。</p>
<h3 id="Corss-sectional回归与选股"><a href="#Corss-sectional回归与选股" class="headerlink" title="Corss-sectional回归与选股"></a><em>Corss-sectional回归与选股</em></h3><p>$$R_{t+1}^i= a + bF_t^i + e_{t+1}^i$$</p>
<p>其中，i代表一个资产，F同样代表信号。针对投资组合中的所有资产进行上述回归分析，得到回归系数矩阵：</p>
<p>$$\hat{b}<em>t=\frac{\sum_i(F_t^i - \bar{F_t})R^i</em>{t+1}}{\sum_i(F_t^i - \bar{F_t})^2} = \sum_{i}x_t^iR_{t+1}^i$$</p>
<p><strong>这个回归系数 $\hat{b}$ 就代表了一个long-short策略在t和t-1获得的收益</strong>。而资产的权重就是：</p>
<p>$$x_t^i=k_t(F_t^i-\bar{F_t})$$</p>
<p>这个回归系数$\hat{b_t}$的平均值，其实就是Fama–MacBeth模型中的系数$\hat{b}$。</p>
<p>$$\hat{b} = 1/T\sum_{t=1}^T\hat{b}_t$$</p>
<p>进而，我们可以求出策略的波动率：</p>
<p>$$\hat{\sigma} = \sqrt{\frac{1}{T-1}\sum_{t=1}^T(\hat{b_t}-\hat{b})^2}$$</p>
<p>这里如果看一下t-static会发现，其实t-statistics就是高夏普比例的表现。</p>
<p>$$tstatistics = \sqrt{T}\frac{\hat{b}}{\hat{\sigma}}$$</p>
<h3 id="多因子回归"><a href="#多因子回归" class="headerlink" title="多因子回归"></a>多因子回归</h3><p>$$R_{t+1}^i= a + b^FF_t^i + b^GG_t^i + e_{t+1}^i$$</p>
<p>在这种情况下，$b^F$ 代表了同时交易信号F和信号G的时候，信号F的收益。</p>
<blockquote>
<p>值得注意的是，时间序列线性回归更加可以，因为用到了信号均值进行计算。而信号均值从回测的角度，属于未来信息。</p>
</blockquote>
<h2 id="构建投资组合以及风险管理"><a href="#构建投资组合以及风险管理" class="headerlink" title="构建投资组合以及风险管理"></a>构建投资组合以及风险管理</h2><p>当我们识别出若干可用的信号以后，就需要组合这些信号形成投资组合进行交易。具体方法多种多样，但是总体原则是：</p>
<ul>
<li>多样性</li>
<li>头寸限制</li>
<li>对信心更强的信号，下注更多</li>
<li>根据风险指标调整投资组合</li>
<li>关注相关性</li>
</ul>
<h2 id="交易的花费"><a href="#交易的花费" class="headerlink" title="交易的花费"></a>交易的花费</h2><ul>
<li>交易花费</li>
<li>funding cost<ul>
<li>总杠杆</li>
<li>净杠杆</li>
</ul>
</li>
<li>Margin</li>
</ul>
<h1 id="2-股票类策略"><a href="#2-股票类策略" class="headerlink" title="2. 股票类策略"></a>2. 股票类策略</h1><p>主要分为三类：discretionary equity, dedicated short bias, and quantitative equities.</p>
<blockquote>
<p>Intrinsic value: It is the discounted value of the cash that can be taken out of a business during its remaining life.</p>
</blockquote>
<p>交易股票的基础在于股票估值，即固有价值。估值的核心在于未来现金流的现今折扣价值：</p>
<p>$$V_t = E_t(\frac{D_{t+1}+V_{t+1}}{1+k_t})$$</p>
<p>其中，k 即使股票的回报率，D 是股票的分红。</p>
<p>不过，分红并不容易预测，特别对于有些成长型的公司，股票并没有分红，所以需要Earning和Book value进行替代计算。</p>
<p>当然，除了上述绝对估值，也可以对股票进行相对估值。</p>
<h2 id="Discretionary-equity"><a href="#Discretionary-equity" class="headerlink" title="Discretionary equity"></a>Discretionary equity</h2><ul>
<li>Value</li>
<li>Growth</li>
<li>Quality</li>
</ul>
<h2 id="Dedicated-short-bias"><a href="#Dedicated-short-bias" class="headerlink" title="Dedicated short bias"></a>Dedicated short bias</h2><h2 id="Quant-equity"><a href="#Quant-equity" class="headerlink" title="Quant equity"></a>Quant equity</h2><ul>
<li>Fundamental quant<ul>
<li>value</li>
<li>quality</li>
<li>bet against beta</li>
</ul>
</li>
<li>Statistic Arb</li>
<li>HFT</li>
</ul>
<h1 id="3、资产配置和宏观策略"><a href="#3、资产配置和宏观策略" class="headerlink" title="3、资产配置和宏观策略"></a>3、资产配置和宏观策略</h1><p>宏观策略的逻辑是自顶向下的，而股票策略则通常是自底向上的。宏观策略的主要受益来源是各种Risk Premiums，比如股票风险回报、时间结构回报（国债）、信誉风险回报（公司债）、流动性风险回报（房地产等）、其他（比如价值引子、趋势、carry等等）。</p>
<p><strong>市场择时</strong></p>
<p>市场择时策略可以通过回归和回测进行分析。</p>
<p><strong>回报率的来源</strong></p>
<h2 id="全球资产配置"><a href="#全球资产配置" class="headerlink" title="全球资产配置"></a>全球资产配置</h2><blockquote>
<p>The whole world is simply nothing more than a flow chart for capital.</p>
</blockquote>
<ul>
<li>Carry</li>
<li>Central banks</li>
</ul>
<h2 id="CTA"><a href="#CTA" class="headerlink" title="CTA"></a>CTA</h2><p>趋势策略，不同时间周期、不同产品的多样性效应。</p>
<h1 id="4、套利策略"><a href="#4、套利策略" class="headerlink" title="4、套利策略"></a>4、套利策略</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/20/cs_app/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/20/cs_app/" class="post-title-link" itemprop="url">Computer System</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-20 00:00:00" itemprop="dateCreated datePublished" datetime="2020-09-20T00:00:00Z">2020-09-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reading/" itemprop="url" rel="index"><span itemprop="name">Reading</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/20/cs_app/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/20/cs_app/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Computer-System-A-Programmer’s-Perspectives"><a href="#Computer-System-A-Programmer’s-Perspectives" class="headerlink" title="Computer System: A Programmer’s Perspectives"></a>Computer System: A Programmer’s Perspectives</h1><p><a href="https://hackmd.io/fzzDuqP9TO2f8MOsqmOxUQ" target="_blank" rel="noopener"><img data-src="https://hackmd.io/fzzDuqP9TO2f8MOsqmOxUQ/badge" alt="hackmd-github-sync-badge"></a></p>
<p>一个读书笔记。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这本书首先自底向上介绍现代计算机的基本工作原理，论述了计算软件和硬件如何协调工作。在此基础上，介绍了一个程序是如何从源代码，被编译，然后被执行的。然后，详细展开说明一个应用程序在硬件和操作系统层面是如何被执行的。 最后，介绍了多个程序之间是如何互动，比如IO、网络、以及并发。</p>
<h2 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h2><p>这本书的角度很独特，作者从一个开发应用程序的程序员角度切入，而不是从操作系统开发人员的角度切入。刚开始读这本书的时候，原本的目的是学习操作系统，但是却意外发现这本书的角度其实非常适合非操作系统开发程序员阅读。因为他深入浅出的解释了很多幕后的事情，读后感觉对整个计算机工作原理有了更加深入的理解，同时也有助于写出更加高效的程序。</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><blockquote>
<p>Information is Bits + Context</p>
</blockquote>
<p>源代码的编译过程：</p>
<p><img data-src="https://i.imgur.com/RBffpof.png" alt="源代码编译"></p>
<p>编译过程主要包含：预处理，编译，汇编，连接等四个过程。预处理主要是扩充源代码的语法糖，比如宏，导入等等；编译器输出汇编版本的程序；汇编器会形成二进制的目标文件；最终，连接器会把各个目标文件组合在一起形成最终的可执行二进制文件。整个过程就是一个把高级语言翻译成二进制指令的过程。</p>
<p>计算机只能执行二进制指令，这些指令通常涉及：读入、存储、计算和跳转。当我们执行一个程序的时候，就是执行编译产生的二进制文件的时候，所有指令和数据会被读入内存，然后CPU通过读取指令和数据完成计算。</p>
<p><img data-src="https://i.imgur.com/ggjMHJJ.png" alt=""></p>
<p>操作系统的主要功能就是提供一个硬件和一般引用程序之间的抽象，为每一个应用程序提供一个进程，也就是一个相对独立的CPU和内存环境。</p>
<p><img data-src="https://i.imgur.com/79exfiM.png" alt=""></p>
<p>计算机的各个部分通过总线连接：</p>
<p><img data-src="https://i.imgur.com/b9gUgiO.png" alt=""></p>
<h2 id="程序的结构"><a href="#程序的结构" class="headerlink" title="程序的结构"></a>程序的结构</h2><h3 id="信息的表达与操作"><a href="#信息的表达与操作" class="headerlink" title="信息的表达与操作"></a>信息的表达与操作</h3><p>word size: 寻址极限，指针的范围。因为1 byte = 8 bit. 所以在64位寻址系统中，一个指针类型由8 byte表达，即64bits。</p>
<p>fix point fraction and floating point fraction。 这里有个不错的参考：<br><a href="https://ryanstutorials.net/binary-tutorial/binary-floating-point.php" target="_blank" rel="noopener">https://ryanstutorials.net/binary-tutorial/binary-floating-point.php</a></p>
<h4 id="整数"><a href="#整数" class="headerlink" title="整数"></a>整数</h4><p>bit wise 运算。</p>
<h4 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h4><p>转化小数到二进制的小数的一种方法：不断给小数部分乘2，取结果整数部分（1或者0）作为该位置的bit，持续进行。</p>
<p>一些“奇怪”的问题，浮点数的代数性质并不能跟真正的小数一致，比如</p>
<ul>
<li>(3.14+1e10) - 1e10 = 0</li>
<li>(1e20<em>1e10)*1e-20 = 无穷，1e20</em>(1e20*1e-20) = 1e20</li>
</ul>
<p>为了避免这些，尽量考虑计算过程中的数值的极值范围，合理处理上面的极端情况。减少两个数量级相差很多的量进行计算， 通常先进行规范化处理后进行计算。</p>
<h3 id="代码的机器层面表达"><a href="#代码的机器层面表达" class="headerlink" title="代码的机器层面表达"></a>代码的机器层面表达</h3><p>源代码经过编译，会形成汇编文件，这个文件其实就是通过简单的指令按顺序排列。只不过在这个阶段，指令使用人类可以理解的单词表达，比如<code>pushl</code>等等。汇编文件经过汇编，就形成了二进制文件，也就是把汇编指令一一对应的翻译成二进制（一般采用16进制表达），如下图所示：</p>
<p><img data-src="https://i.imgur.com/LkwkUrY.png" alt=""></p>
<h3 id="提高速度的一些小技巧"><a href="#提高速度的一些小技巧" class="headerlink" title="提高速度的一些小技巧"></a>提高速度的一些小技巧</h3><ol>
<li>减少循环</li>
<li>循环中减少函数调用</li>
<li>使用局部变量</li>
</ol>
<h2 id="程序的执行"><a href="#程序的执行" class="headerlink" title="程序的执行"></a>程序的执行</h2><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>这里的异常处理指的是硬件或者操作系统层面的异常，不是高级语言中的异常处理。</p>
<p>在硬件层面，异常主要分成四种：</p>
<ul>
<li>Interrupt，异步，通常由IO造成</li>
<li>Trap,同步，一般是操作系统内核制造</li>
<li>Fault，同步，可恢复的错误产生</li>
<li>Abort，同步，不可恢复的错误产生</li>
</ul>
<p>其中，只有Interrupt是异步的，因为它是由CPU外部的设备产生的，而其他异常都是CPU执行指令的结果。</p>
<h3 id="进程，Processes"><a href="#进程，Processes" class="headerlink" title="进程，Processes"></a>进程，Processes</h3><p>异常处理是系统实现进程抽象的基本方法，每一个运行在操作系统上的程序都有自己的进程，进程中包含了程序的代码、数据、盏、寄存器状态等等。进程提供了两个基本的抽象：</p>
<ul>
<li>独立的逻辑控制流程</li>
<li>独立的私有内存空间</li>
</ul>
<p>有了这个两个抽象，每一个程序就好像独占整个电脑一样。每一个进程都至少有一个进程ID，PID，如果是子进程，还会有对应的子进程pid。从程序员的角度看，一个进程有三种状态：running, stopped, terminated。</p>
<p><code>fork</code>可以用来创建进程或者子进程。<code>execve</code> 可以用来执行一段程序。程序与进程是不同的，程序通常只是一段代码加数据，而进程则是一系列的计算资源、内存、IO等等。通常一个程序需要在进程中运行。</p>
<h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>虚拟内存，Virtual Memory，是另一个非常重要的抽象。VM主要有三个功能：</p>
<ul>
<li>物理内存成为虚拟内存地址的高速缓存</li>
<li>实现了每一个进程独立的虚拟内存空间</li>
<li>确保不同进程的内存空间不发生冲突</li>
</ul>
<p>Memory management unit, MMU, is the hardware that translate virtual addresses to physical addresses. </p>
<p>虚拟内存的基本思想就是区分数据本身和数据属性，比如地址并不是数据本身，而是数据的一个属性，因此，同一个数据可以具有不同的地址属性。因此，每一个字节（Byte）的内存空间都有一个物理地址和一个虚拟地址。</p>
<blockquote>
<p>任何计算机问题都可以通过增加重新定向解决，Mapping。</p>
</blockquote>
<h3 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h3><p><img data-src="https://i.imgur.com/PPKEmBj.png" alt=""></p>
<h2 id="程序的互动"><a href="#程序的互动" class="headerlink" title="程序的互动"></a>程序的互动</h2><h3 id="系统IO"><a href="#系统IO" class="headerlink" title="系统IO"></a>系统IO</h3><p>Input/Output，IO，指的是内存和其他外设之间的数据传输过程。Input，从外部设备拷贝数据进入内存；Output，从内存传输数据进入外部设备。外部设备可以是硬盘、终端、网络等等。</p>
<p>系统内核，Kernel，提供了基本的IO操作。在Unix类系统中，所有的I/O设备，例如网络、硬盘、终端等，都用文件表达，所有的输入、输出都已读写对应的文件完成。文件，就是一些列的字节。</p>
<p>注意到，这里出现了另一个重新定向，Mapping：I/O设备到文件。通过文件映射，统一了各类外设的操作方法。跟虚拟内存异曲同工。</p>
<p><img data-src="https://i.imgur.com/vPBnwkw.png" alt=""></p>
<h3 id="网络IO"><a href="#网络IO" class="headerlink" title="网络IO"></a>网络IO</h3><p>Socket Interface.</p>
<p><img data-src="https://i.imgur.com/QcA0tVp.png" alt=""></p>
<h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><p>这里是应用层面的并发。操作系统提供了三种并发方法：</p>
<ul>
<li>Process,进程</li>
<li>I/O multiplexing</li>
<li>Thread，线程</li>
</ul>
<p>线程实现可以看成是Process和Multiplexing的结合，多个线程在同一个进程中，因此共享内存，但是程序执行的schedule是由系统内核完成的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/01/rl4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/01/rl4/" class="post-title-link" itemprop="url">Reinforment Learning 4 Dynamic Programming</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-01 00:00:00" itemprop="dateCreated datePublished" datetime="2020-08-01T00:00:00Z">2020-08-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Quant/" itemprop="url" rel="index"><span itemprop="name">Quant</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/08/01/rl4/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/08/01/rl4/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In previous chapter, value functions are defined. Dynamic Programming method is used here to use value functions to organize and structure the search for agent best policy.</p>
<p><img data-src="https://i.imgur.com/26qVDFu.png" alt=""></p>
<p><img data-src="https://i.imgur.com/YFH5OcT.png" alt=""></p>
<p>In other words, DP algorithms are obtained by turning Bellman equations such as these into assignments, that is, into update rules for improving approximations of the desired value functions.</p>
<h2 id="Policy-Evaluation"><a href="#Policy-Evaluation" class="headerlink" title="Policy Evaluation"></a>Policy Evaluation</h2><p>First thing, how can we compute value function $v_{\pi}$ given a policy? This is also known as <em>prediction problem</em> or <em>policy evaluation</em>. </p>
<p><img data-src="https://i.imgur.com/GBtvnIv.png" alt=""></p>
<p>As above, there is a iterative method that we can solve this recursive problem.</p>
<p><img data-src="https://i.imgur.com/qwEAxdf.png" alt=""></p>
<p>TODO: code to simulate Grid world value functions</p>
<h2 id="Policy-Improvement"><a href="#Policy-Improvement" class="headerlink" title="Policy Improvement"></a>Policy Improvement</h2><p>The theory is simple. If $q_{\pi}(s,\pi’(s)) \gt v_{\pi}(s)$, then $\pi’$ must be as good as, or better than, $\pi$ . Hence $v_{\pi’}(s) \gt v_{\pi}(s)$</p>
<p><img data-src="https://i.imgur.com/Yrw6w2t.png" alt=""></p>
<p>Or in another equation:</p>
<p><img data-src="https://i.imgur.com/NMnxuE7.png" alt=""></p>
<p>TODO：code</p>
<h2 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h2><p>Once we know how to compute value function and how to improve a policy using value function, we can iterate the process to get a optimal policy.</p>
<p><img data-src="https://i.imgur.com/39yUEIw.png" alt=""></p>
<h2 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h2><p><img data-src="https://i.imgur.com/kfwyLJf.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/31/rl2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/31/rl2/" class="post-title-link" itemprop="url">Reinforment Learning 3 Markov Decision Process</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-31 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-31T00:00:00Z">2020-07-31</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Quant/" itemprop="url" rel="index"><span itemprop="name">Quant</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/31/rl2/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/31/rl2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Markov-Decision-Process-MDP"><a href="#Markov-Decision-Process-MDP" class="headerlink" title="Markov Decision Process, MDP"></a>Markov Decision Process, MDP</h1><p><a href="https://hackmd.io/BGkR2gTjTLy6oHBfkQ2EAQ" target="_blank" rel="noopener"><img data-src="https://hackmd.io/BGkR2gTjTLy6oHBfkQ2EAQ/badge" alt="hackmd-github-sync-badge"></a></p>
<h2 id="High-level-overview-of-RL"><a href="#High-level-overview-of-RL" class="headerlink" title="High level overview of RL"></a>High level overview of RL</h2><p>At the heart of RL theory, it is Markov Decision Process.</p>
<p>The general rule we follow is that anything that cannot be changed arbitrarily by the agent is considered to be outside of it and thus part of its environment.</p>
<p>High level description of RL problem: three signals.</p>
<p>The <strong>representation</strong> of the signals (actions and states) is art! Reword, on the other hand, is always real numbers. (why?? this does not sound good!!! Not consistent with actions and states which have complex representation!!)</p>
<p>Two types of RL tasks: episodic task and continuing task.</p>
<p>The reward for both cases: </p>
<p>$$G_t = \sum_{k=0}^{T-t-1}\gamma^k R_{t+k+1}$$</p>
<p>where, $T$ can be infinite and $\gamma$ can be 1.</p>
<h2 id="The-Markov-Property"><a href="#The-Markov-Property" class="headerlink" title="The Markov Property"></a>The Markov Property</h2><p>Here we don’t discuss the design of state signal, because I focus on form the RL problem framework. However, the design of the states representation is very important in terms of make a good RL model.</p>
<p>State representation can be very complicated and not expected to inform the agent everything about the environment. </p>
<p>A state signal that succeeds in retaining all relevant information is said to be Markov, or to have the <strong>Markov property</strong>.</p>
<p>The dynamic of environment is a joint distribution of states and rewards:</p>
<p>$$Pr{R_{t+1}=r, S_{t+1}=s’|S_0,A_0,R_1,…,S_t, A_t}$$</p>
<p>If state signal has the Markov property, we have</p>
<p>$$p(s’,r|s,a) = Pr{R_{t+1}=r, S_{t+1}=s’|S_t, A_t}$$</p>
<p>In order for these to be effective and informative, the state representation must be informative.</p>
<h2 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h2><p>Expected rewords for state-action pairs:</p>
<p><img data-src="https://i.imgur.com/64vtOf2.png" alt=""></p>
<p>The state-transition probability:</p>
<p><img data-src="https://i.imgur.com/eqZhGEy.png" alt=""></p>
<p>The expected rewards for state-action-next-state triples:</p>
<p><img data-src="https://i.imgur.com/7xgrcZX.png" alt=""></p>
<h2 id="Value-functions"><a href="#Value-functions" class="headerlink" title="Value functions"></a>Value functions</h2><p>Value functions estimation how good is a state in terms of the goal. Accordingly, value functions are defined with respect to particular policies.</p>
<p>For MDPs, we can define $v_{\pi}(s)$ formally as</p>
<p>$$v_{\pi}(s)=\mathbb{E}_{\pi}[G_t|S_t=s]$$</p>
<p>where, $G_t = \sum_{k=0}^{\infty}\gamma^kR_{t+k+1}$.</p>
<p>Similarly, we can define the value of taking action a in state s under a policy:</p>
<p>$$q_{\pi}(s, a) = \mathbb{E}_{\pi}[G_t | S_t=s, A_t=a]$$</p>
<p>A fundamental property of value function is that they satisfy particular recursive relationships.</p>
<p>$$v_{\pi} = \sum_{a}\pi(a|s)\sum_{s’,r}p(s’,r|s,a)[r+\gamma v_{\pi}(s’)]$$</p>
<p>This is <strong>Bellman equation</strong>.</p>
<h2 id="Optimal-Value-Functions"><a href="#Optimal-Value-Functions" class="headerlink" title="Optimal Value Functions"></a>Optimal Value Functions</h2><p>Solving a reinforcement learning task means, roughly, finding a policy that achieves a lot of reward over the long run. </p>
<p>$$q_{<em>}=\mathbb{E}[R_{t+1}+\gamma v_{</em>}(S_{t+1})|S_t=s,A_t=a]$$</p>
<p>We have</p>
<p>$$v_{<em>}=max\sum_{s’,r}p(s’,r|s,a)[r+\gamma v_{</em>}(s’)], for all A(s)$$</p>
<p>$$q_{<em>}(s,a) = \sum_{s’,r}p(s’,r|s,a)[r + \gamma max q_{</em>}(s’,a’)]$$</p>
<p>These are Bellman optimality equation.</p>
<h2 id="Bellman-Equations"><a href="#Bellman-Equations" class="headerlink" title="Bellman Equations"></a>Bellman Equations</h2><p><img data-src="https://i.imgur.com/Ln7PnVy.png" alt=""></p>
<p>The are relationships between value function and q-function:</p>
<p><img data-src="https://i.imgur.com/YEGGt2x.png" alt=""></p>
<p>Our goal in RL is to solve Bellman Optimality Equation. There are two ways of solving this non-linear problem:</p>
<ul>
<li>Dynamic Programming, this when you have a model of the MDP.<ul>
<li>Value iteration</li>
<li>Policy iteration</li>
</ul>
</li>
<li>Sampling <ul>
<li>Monte Carlo</li>
<li>Q-learning</li>
<li>Sarsa</li>
</ul>
</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>Reinforcement learning is about learning from interaction how to behave in order to achieve a goal.</li>
<li>the actions are the choices made by the agent; the states are the basis for making the choices; and the rewards are the basis for evaluating the choices.</li>
<li>A policy is a stochastic rule by which the agent selects actions as a function of states. The agent’s objective is to maximize the amount of reward it receives over time.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/26/yisaiya55/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/26/yisaiya55/" class="post-title-link" itemprop="url">接受来自造物主的邀请 - 以赛亚书 55</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-26 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-26T00:00:00Z">2020-07-26</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bible/" itemprop="url" rel="index"><span itemprop="name">Bible</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/26/yisaiya55/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/26/yisaiya55/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="接受来自造物主的邀请-以赛亚书-55"><a href="#接受来自造物主的邀请-以赛亚书-55" class="headerlink" title="接受来自造物主的邀请 - 以赛亚书 55"></a>接受来自造物主的邀请 - 以赛亚书 55</h1><h2 id="难以拒绝的邀请-1-5-x1f4e8"><a href="#难以拒绝的邀请-1-5-x1f4e8" class="headerlink" title="难以拒绝的邀请 1-5 &#x1f4e8;"></a>难以拒绝的邀请 1-5 <span class="github-emoji" alias="incoming_envelope" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e8.png?v8">&#x1f4e8;</span></h2><blockquote>
<p>看哪!你要召聚你不认识的国; 那些素来不认识你的国也必奔向你， 都因耶和华你的 神、以色列的圣者的缘故， 因为他已经荣耀了你。</p>
</blockquote>
<p>神通过自己的仆人，耶稣基督，承受罪的后果，已经把救赎带给了全世界。值得注意的是，先知以赛亚的世代，耶稣基督来没有降临，以色列作为神当时的仆人，并没有看到基督的降临。但是，先知在这里把时间推移到了未来，真正的仆人已经到来，救赎已经到来。(￣▽￣)</p>
<blockquote>
<p>你们为甚么用银子去买那不是食物的呢? 为甚么用你们劳碌得来的去买那不能使人饱足的呢? 你们要留心听我的话，就可以吃美物， 使你们的心灵享受肥甘。</p>
</blockquote>
<p>先知用免费的宴会的比喻，来说明神救赎的邀请。但是他说道，被邀请的人都是“穷人”，因为神的救赎只能来自神的怜悯，并不是我们可以用自己的努力换取的。这个救赎的邀请，是给所有谦卑的人的，所有愿意承认自己无能为力得到救赎的人的。</p>
<h2 id="尽快的回应-6-7-x2139"><a href="#尽快的回应-6-7-x2139" class="headerlink" title="尽快的回应 6-7 &#x2139;"></a>尽快的回应 6-7 <span class="github-emoji" alias="information_source" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2139.png?v8">&#x2139;</span></h2><blockquote>
<p>6 你们要趁着耶和华可以寻找的时候，寻找他，趁着他靠近的时候，呼求他。7 恶人要离弃自己的道路， 不义的人当除去自己的意念， 回转过来归向耶和华， 耶和华就必怜悯他。你们当回转过来归向我们的 神， 因为他大大赦免人的罪。</p>
</blockquote>
<p>当然，这个邀请不是无限期的，先知这里强调，你们要寻找他、靠近他、呼求他。就好像迷路的人，应该大声呼救。而且，他也提醒人们，快速的离开错误的道路，认罪，回到神的道路上。</p>
<p>先知提到，你要趁着耶和华还在寻找的时候，归向他。因为救赎的大门不会永远开放，要在大门关闭前会转相信。</p>
<h2 id="万无一失的救赎-8-13-x2139"><a href="#万无一失的救赎-8-13-x2139" class="headerlink" title="万无一失的救赎 8-13 &#x2139;"></a>万无一失的救赎 8-13 <span class="github-emoji" alias="information_source" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2139.png?v8">&#x2139;</span></h2><p>这救赎是来自造物主的，这救赎的完美超过我们的理智所能推测的，我们必须紧紧依靠神的话语，依靠着完备的救赎。</p>
<blockquote>
<p>8 耶和华说:“我的意念不是你们的意念， 你们的道路也不是我的道路。<br>9 天怎样高过地， 我的道路也怎样高过你们的道路， 我的意念也怎样高过你们的意念。<br>11 从我的口所出的话也必这样， 必不徒然返回我这里， 却要作成我所喜悦的， 使它在我差遣它去作的事上必然亨通。</p>
</blockquote>
<p>我们有理由信靠这个邀请，因为这个邀请来自宇宙的造物主 神。当然，这意味着，我们只能通过相信来接受救赎，而不是完全依靠理智，因为我们没有能力完全理解神的心思意念。</p>
<p>造物主 神，也保证：“从我的口所出的话也必这样， 必不徒然返回我这里”。神，从不食言。神，通过话语实现创造，也通过话语实现救赎。</p>
<h2 id="基督徒-x271d"><a href="#基督徒-x271d" class="headerlink" title="基督徒 &#x271d;"></a>基督徒 <span class="github-emoji" alias="latin_cross" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/271d.png?v8">&#x271d;</span></h2><p>当我们困倦的时候，应该时常思考神的话语，因为他的话语绝不落空。虽然，可能我们可能不理解为什么许多坏事情发生在自己身上、发生在世界上，但是我们应该记得，神的话语、心思都高于人的理解。</p>
<p>新天地降临后，你绝对不会后悔经历的一切忍耐。救恩，已经成就了。</p>
<p><span class="github-emoji" alias="latin_cross" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/271d.png?v8">&#x271d;</span> </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/25/rl1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/25/rl1/" class="post-title-link" itemprop="url">Reinforment Learning Introduction 1 - 2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-25T00:00:00Z">2020-07-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Quant/" itemprop="url" rel="index"><span itemprop="name">Quant</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/25/rl1/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/25/rl1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a href="https://hackmd.io/EF3LjEjfQtCa-yEZlFNCmQ" target="_blank" rel="noopener"><img data-src="https://hackmd.io/EF3LjEjfQtCa-yEZlFNCmQ/badge" alt="hackmd-github-sync-badge"></a></p>
<p>Reinforcement learning, RL is a framework that let an agent to make suitable  decisions to achieve best goal. Underneath math problem to solve is a  Markov Decision Process, MDP.  RL is different from both supervised and unsupervised learning. </p>
<h1 id="Elements-of-RL"><a href="#Elements-of-RL" class="headerlink" title="Elements of RL"></a>Elements of RL</h1><p>Apart from Agent and Environment, following elements also play central<br>roles: Policy, Reward Signal, Value Function, and Model of environment. </p>
<p>Policy, is a map from current states to actions to take. It might be<br>deterministic or stochastic.</p>
<p>Reword signal, defines the goal of RL. At each step, environment will<br>give agent a single number, a reward.</p>
<p>Value function, specifies what is good in the long run. The estimation<br>of value is in the central part of RL.</p>
<p>Model, is what the agent think the environment will behave. Basically by<br>building a model of env, the agent can do planning better. But model env<br>sometime is very hard.</p>
<p>Not all RL model need full set of above. But a good value function does<br>help to make a better decision.In the end, evolutionary and value function methods both search the space of policies, but learning a value function takes advantage of information available during the course of play.</p>
<h1 id="A-bit-history"><a href="#A-bit-history" class="headerlink" title="A bit history"></a>A bit history</h1><p>There are two threads of RL histories. One thread concerns learning by trial and error that started in the psychology of animal learning. The other thread concerns the problem of optimal control and its solution using value functions and dynamic programming. </p>
<p>Although the two threads have been largely independent, the exceptions revolve around a third, less distinct thread concerning temporal-difference methods</p>
<h1 id="Simplest-problem-Multi-arm-Bandits"><a href="#Simplest-problem-Multi-arm-Bandits" class="headerlink" title="Simplest problem: Multi-arm Bandits"></a>Simplest problem: Multi-arm Bandits</h1><p>The most important feature distinguishing reinforcement learning from other types of learning is that it uses training information that evaluates the actions taken rather than instructs by giving correct actions.</p>
<p>Consider the following learning problem. You are faced repeatedly with a choice among n different options, or actions. After each choice you receive a numerical reward chosen from a stationary probability distribution that depends on the action you selected. Your objective is to maximize the expected total reward over some time period, for example, over 1000 action selections, or time steps.</p>
<h2 id="Action-Value-method"><a href="#Action-Value-method" class="headerlink" title="Action Value method"></a>Action Value method</h2><p>Assume $q(a)$ is the true value of action a, and the estimation on t step is $Q_t(a)$. Then the simplest idea is average: </p>
<p>$$Q_t(a) = \frac {R_1+ R_2 + … + R_{N_t(a)}}{N_t(a)}$$</p>
<p>Once we have $Q_t(a)$, we can then select the action with highest estimated action value. The <em>greedy</em> action selection method can be written as</p>
<p>$$A_t = argmax Q_t(a)$$</p>
<p>Greedy means that action selection always <strong>exploits</strong> currently knowledge to max immediate reward. A simple alternative is to behave greedily most of the time, but, <strong>explore</strong> new actions sometimes.</p>
<h2 id="Incremental-Implementation"><a href="#Incremental-Implementation" class="headerlink" title="Incremental Implementation"></a>Incremental Implementation</h2><p>$$Q_{k+1} = Q_k + \frac {1}{k}[R_k - Q_k]$$</p>
<p>So esentially, update previous estimation with adjustment of new update.</p>
<p>$$NewEstimate \leftarrow OldEstimate + StepSize * [Target - OldEstimate]$$</p>
<h2 id="Nonstationary-Problem"><a href="#Nonstationary-Problem" class="headerlink" title="Nonstationary Problem"></a>Nonstationary Problem</h2><p>For non-stationary problem, it makes more sense to has more weights on recent result.</p>
<p>$$Q_{k+1} = Q_k + \alpha [R_k - Q_k]$$</p>
<p>$$Q_{k+1} = (1-\alpha)^kQ_1 + \sum_{i=1}^k\alpha(1-\alpha)^{k-i}R_i$$</p>
<h2 id="Upper-Confidence-Bound-Action-Selection"><a href="#Upper-Confidence-Bound-Action-Selection" class="headerlink" title="Upper-Confidence-Bound Action Selection"></a>Upper-Confidence-Bound Action Selection</h2><p>$$A_t = argmax_a\Big[Q_t(a) + c\sqrt{\frac{ln t}{N_t(a)}}\Big]$$</p>
<p>The idea here is to add exploration more wisely. So if an action is not selected for a long time, it is more likely to be selected, and if an action has been selected a lot of time, it is more likely to be selected (stick with optimal action, i.e. exploiate. )</p>
<h2 id="Gradient-Bandits"><a href="#Gradient-Bandits" class="headerlink" title="Gradient Bandits"></a>Gradient Bandits</h2><p>we can also learn a preference of each action, $H_t(a)$. The more preference, the more change to take that action. But preference is a relative value.</p>
<p>$$\pi_{t}(a) = P{A_t=a} = \frac {e^{H_t(a)}}{\sum_{b=1}^{n}e^{H_t(b)}}$$</p>
<p>So action is a softmax of preferences. We want to learn the preference of each actions.</p>
<p>Initially, all preference is 0.</p>
<p>So the learning/updating process is:</p>
<p>$$H_{t+1}(A_t) = H_t(A_t) + \alpha(R_t - \bar{R_t})(1 - \pi_{t}(A_t))$$</p>
<p>$$H_{t+1}(a) = H_t(a) - \alpha(R_t - \bar{R_t}\pi_t(a), \forall{a} \ne A_t$$</p>
<p>Above is a stochastic approximation to gradient ascent:</p>
<p>$$H_{t+1}(a) = H_t(a) + \alpha \frac {\partial {E[R_t]}} {\partial {H_t(a)}}$$</p>
<p>where, $E[R_t] = \sum_{b}\pi_t(b)q(b)$</p>
<h1 id="Different-Agents-of-Mult-arm-Bandits"><a href="#Different-Agents-of-Mult-arm-Bandits" class="headerlink" title="Different Agents of Mult-arm Bandits"></a>Different Agents of Mult-arm Bandits</h1><h2 id="Random-Agent"><a href="#Random-Agent" class="headerlink" title="Random Agent"></a>Random Agent</h2><p>The agent pick action randomly from action space, <code>number_of_arms</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Random</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""A random agent.</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  This agent returns an action between 0 and 'number_of_arms', </span></span><br><span class="line"><span class="string">  uniformly at random. The 'previous_action' argument of 'step'</span></span><br><span class="line"><span class="string">  is ignored.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number_of_arms)</span>:</span></span><br><span class="line">    self._number_of_arms = number_of_arms</span><br><span class="line">    self.name = <span class="string">'random'</span></span><br><span class="line">    self.reset()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, previous_action, reward)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.random.randint(self._number_of_arms)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="Greedy-Agent"><a href="#Greedy-Agent" class="headerlink" title="Greedy Agent"></a>Greedy Agent</h2><p>The agent pick action that has most big expected value.</p>
<p>So pick action as following:</p>
<p>$$A_t = argmax Q_t(a)$$</p>
<p>Every step, update Q value of previous actions and counter of actions:</p>
<p>$$N(A_{t-1}) = N(A_{t-1}) + 1$$<br>$$Q(A_{t-1}) = Q(A_{t-1}) + \alpha(R_t - Q(A_{t-1}))$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Greedy</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number_of_arms)</span>:</span></span><br><span class="line">    self._number_of_arms = number_of_arms</span><br><span class="line">    self.name = <span class="string">'greedy'</span></span><br><span class="line">    self.reset()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, previous_action, reward)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> type(previous_action) == type(<span class="literal">None</span>):</span><br><span class="line">      <span class="keyword">return</span> np.random.randint(self._number_of_arms)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="comment"># update values</span></span><br><span class="line">      self.N[previous_action] += <span class="number">1</span></span><br><span class="line">      lr = <span class="number">1.</span>/self.N[previous_action]</span><br><span class="line">      error = reward - self.Q[previous_action]</span><br><span class="line">      self.Q[previous_action] += lr*error</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># get new actions</span></span><br><span class="line">      <span class="keyword">return</span> np.argmax(self.Q)</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.Q = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">    self.N = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="epsilon-Greedy-Agent"><a href="#epsilon-Greedy-Agent" class="headerlink" title="$\epsilon$-Greedy Agent"></a>$\epsilon$-Greedy Agent</h2><p>The issue of pure greedy agent is that it may stuck in some false action and never explore. So we add a small change to select action which does not have best q value, but just to explore to gather more information.</p>
<p>The update process is as same as Greedy agent. But the way we choose actions changed:</p>
<p>$$A_t = argmax Q, rand &gt; \epsilon$$<br>$$A_t = random action, rand &lt;= \epsilon$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EpsilonGreedy</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number_of_arms, epsilon=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    self._number_of_arms = number_of_arms</span><br><span class="line">    self._epsilon = epsilon</span><br><span class="line">    self.name = <span class="string">'epsilon-greedy epsilon:&#123;&#125;'</span>.format(epsilon)</span><br><span class="line">    self.reset()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, previous_action, reward)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> type(previous_action) == type(<span class="literal">None</span>):</span><br><span class="line">      <span class="keyword">return</span> np.random.randint(self._number_of_arms)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="comment"># update values</span></span><br><span class="line">      self.N[previous_action] += <span class="number">1</span></span><br><span class="line">      lr = <span class="number">1.</span>/self.N[previous_action]</span><br><span class="line">      error = reward - self.Q[previous_action]</span><br><span class="line">      self.Q[previous_action] += lr*error</span><br><span class="line"></span><br><span class="line">      <span class="comment"># get new actions</span></span><br><span class="line">      ra = bool( np.random.random() &lt; self._epsilon )</span><br><span class="line">      <span class="keyword">return</span> (<span class="keyword">not</span> ra) * np.argmax(self.Q) + (ra) * np.random.randint(self._number_of_arms)</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.Q = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">    self.N = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">`</span><br></pre></td></tr></table></figure>

<h2 id="UCB-Agent"><a href="#UCB-Agent" class="headerlink" title="UCB Agent"></a>UCB Agent</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UCB</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number_of_arms)</span>:</span></span><br><span class="line">    self._number_of_arms = number_of_arms</span><br><span class="line">    self.name = <span class="string">'ucb'</span></span><br><span class="line">    self.reset()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, previous_action, reward)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> type(previous_action) == type(<span class="literal">None</span>):</span><br><span class="line">      <span class="keyword">return</span> np.random.randint(self._number_of_arms)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.t += <span class="number">1</span></span><br><span class="line">      <span class="comment"># update values</span></span><br><span class="line">      self.N[previous_action] += <span class="number">1</span></span><br><span class="line">      lr = <span class="number">1.</span>/self.N[previous_action]</span><br><span class="line">      error = reward - self.Q[previous_action]</span><br><span class="line">      self.Q[previous_action] += lr*error</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># here is the extra bit</span></span><br><span class="line">      U = np.sqrt(np.log(self.t)/<span class="number">1.</span>/(self.N+<span class="number">1.</span>))</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># get new actions</span></span><br><span class="line">      <span class="keyword">return</span> np.argmax(self.Q+U)</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.Q = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">    self.N = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">    self.t = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="Reinforce-Agent"><a href="#Reinforce-Agent" class="headerlink" title="Reinforce Agent"></a>Reinforce Agent</h2><p>Base line will not affect mean, but will change the variance of the estimation. </p>
<p>After we have the policy, we can sample an action from the policy.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Reinforce</span><span class="params">(object)</span>:</span></span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number_of_arms, step_size=<span class="number">0.1</span>, baseline=False)</span>:</span></span><br><span class="line">    self._number_of_arms = number_of_arms</span><br><span class="line">    self._lr = step_size</span><br><span class="line">    self.name = <span class="string">'reinforce, baseline: &#123;&#125;'</span>.format(baseline)</span><br><span class="line">    self._baseline = baseline</span><br><span class="line">    self.reset()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, previous_action, reward)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> type(previous_action) == type(<span class="literal">None</span>):</span><br><span class="line">      <span class="keyword">return</span> np.random.randint(self._number_of_arms)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.t += <span class="number">1</span></span><br><span class="line">      self.all_reward += reward</span><br><span class="line">      <span class="keyword">if</span> self._baseline:</span><br><span class="line">        base = self.all_reward / (self.t * <span class="number">1.</span>)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        base = <span class="number">0</span></span><br><span class="line">      <span class="comment"># update preferences</span></span><br><span class="line">      <span class="comment"># this is H_a, reduce others preference</span></span><br><span class="line">      self.prob -= self._lr * (reward-base) * self.policy</span><br><span class="line">      <span class="comment"># this is H_A, increase current action preference</span></span><br><span class="line">      self.prob[previous_action] += self._lr * (reward-base)</span><br><span class="line">      x = self.prob</span><br><span class="line">      y = np.exp(x - np.max(x))</span><br><span class="line">      self.policy = y / np.sum(y)</span><br><span class="line">      <span class="comment"># get new actions</span></span><br><span class="line">      <span class="comment"># here we sample an action from the updated policy</span></span><br><span class="line">      <span class="keyword">import</span> bisect</span><br><span class="line">      acc = np.cumsum(self.policy)</span><br><span class="line">      <span class="keyword">return</span> bisect.bisect(acc, np.random.random())</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.policy = np.ones((self._number_of_arms,),dtype=<span class="string">'float32'</span>)/self._number_of_arms</span><br><span class="line">    self.prob = np.zeros((self._number_of_arms,),dtype=<span class="string">'float32'</span>)</span><br><span class="line">    self.t = <span class="number">0</span></span><br><span class="line">    self.all_reward = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h1 id="Full-RL-Problem"><a href="#Full-RL-Problem" class="headerlink" title="Full RL Problem"></a>Full RL Problem</h1><p>Above problem is not a full RL problem, because there is no association between action and different situations. Full RL problem needs to learn a policy that maps situations to actions.</p>
<h1 id="Bandit-Env-Code-Attached"><a href="#Bandit-Env-Code-Attached" class="headerlink" title="Bandit Env Code Attached"></a>Bandit Env Code Attached</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BernoulliBandit</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""A stationary multi-armed Bernoulli bandit."""</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, success_probabilities, success_reward=<span class="number">1.</span>, fail_reward=<span class="number">0.</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Constructor of a stationary Bernoulli bandit.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      success_probabilities: A list or numpy array containing the probabilities,</span></span><br><span class="line"><span class="string">          for each of the arms, of providing a success reward.</span></span><br><span class="line"><span class="string">      success_reward: The reward on success (default: 1.)</span></span><br><span class="line"><span class="string">      fail_reward: The reward on failure (default: 0.)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self._probs = success_probabilities</span><br><span class="line">    self._number_of_arms = len(self._probs)</span><br><span class="line">    self._s = success_reward</span><br><span class="line">    self._f = fail_reward</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, action)</span>:</span></span><br><span class="line">    <span class="string">"""The step function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      action: An integer or tf.int32 that specifies which arm to pull.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A sampled reward according to the success probability of the selected arm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">      ValueError: when the provided action is out of bounds.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> action &lt; <span class="number">0</span> <span class="keyword">or</span> action &gt;= self._number_of_arms:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Action &#123;&#125; is out of bounds for a '</span></span><br><span class="line">                       <span class="string">'&#123;&#125;-armed bandit'</span>.format(action, self._number_of_arms))</span><br><span class="line"></span><br><span class="line">    success = bool(np.random.random() &lt; self._probs[action])</span><br><span class="line">    reward = success * self._s + (<span class="keyword">not</span> success) * self._f</span><br><span class="line">    <span class="keyword">return</span> reward</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/19/yisaiya5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/19/yisaiya5/" class="post-title-link" itemprop="url">神的仆人成就的救恩 - 以赛亚书54</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-19 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-19T00:00:00Z">2020-07-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bible/" itemprop="url" rel="index"><span itemprop="name">Bible</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/19/yisaiya5/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/19/yisaiya5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>以赛亚书54章有两个主题，其一，神承诺与他的子民和好；其二，神的城市一定会被重新建立。</p>
<blockquote>
<p>9 这事对我就好象挪亚时代的洪水一般; 我怎样起誓不再使挪亚时代的洪水漫过大地， 我也照样起誓不向你发怒，也不斥责你。10 虽然大山可以挪开，小山可以迁移，但我的慈爱必不从你身上挪开， 我和平的约也必不迁移; 这是怜悯你的耶和华说的。 《以赛亚书 54》</p>
</blockquote>
<p>神应许会收回怒气，把慈爱加给世界。</p>
<blockquote>
<p>11 受困苦、被风飘荡、不得安慰的啊! 你看，我要用彩色的石头安置你的基石，以蓝宝石奠定你的根基。 12 又用红宝石做你的城楼，用红玉做你的城门，用各种宝石做你四周的围墙。13 你所有的儿女都必受耶和华的教导，14 耶和华这样说: 你的儿女必大享平安。<br>《以赛亚书 54》</p>
</blockquote>
<p>这里以赛亚预言了未来完美的城池，而且所有神的儿女都可以得到神的教导。就是我们的圣经。当今世界，我们已经可以轻松的得到耶和华的教导。</p>
<p>这些都是靠着以赛亚口中那个受苦的仆人，就是耶稣基督，成就的事情。</p>
<p>这经文也会影响我们如何看待目前世界的种种问题，比如新冠疫情、战争、饥饿等等，这些都不是神审判，因为审判已经加给耶稣基督。我们需要持续的信靠，知道主再来。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/08/shipian/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/08/shipian/" class="post-title-link" itemprop="url">神的创造与律法 诗篇19</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-08 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-08T00:00:00Z">2020-07-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bible/" itemprop="url" rel="index"><span itemprop="name">Bible</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/08/shipian/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/08/shipian/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>1诸天述说　神的荣耀，穹苍传扬他的作为。 2天天发出言语，夜夜传出知识。</p>
</blockquote>
<p>大卫，写了一首歌来称赞神的伟大。神的创造和神的律法都在反映神的荣耀。</p>
<h2 id="宇宙"><a href="#宇宙" class="headerlink" title="宇宙"></a>宇宙</h2><p>宇宙万物都在彰显神的存在和伟大。宇宙就好像在用口述说神的荣耀。</p>
<p>大卫的时代，人们通常愿意崇拜宇宙中的事物，比如太阳、月亮和星辰。但是，人们却忽略了一个事实：神是宇宙的创造者。他才是唯一值得崇拜的。</p>
<p>我们的时代，人们不再崇拜太阳和星辰，人们崇拜科学，这些科学让然在是解释宇宙万物。同样的，人们仍然忽略了同一个事实：神是宇宙的创造者。</p>
<p>宇宙，确实是伟大的；但是，他的创造者才是一切的来源，宇宙的存在就是为了彰显他的荣耀。</p>
<p>任何时代，我们都不应该弄错主次。</p>
<h2 id="律法"><a href="#律法" class="headerlink" title="律法"></a>律法</h2><blockquote>
<p>7耶和华的律法是完全的，能使人心苏醒；耶和华的法度是坚定的，能使愚人有智慧。</p>
</blockquote>
<p>神的律法让人充满智慧，智慧始于认识耶和华。神的话语是完备的，拥有无比的价值。</p>
<p>神的话语让人充满喜乐。</p>
<p>我们的时代，有太多的话语、声音，我们应该听从哪一个？答案很明显：神的话语。</p>
<p>在漫长的人类历史中，我们发展出来很多理论和哲学，但是一个不争的事实是：所以的哲学和理论都不是完整的，都不能经过时间的考验。但是神的话语拥有完全不用的属性。</p>
<blockquote>
<p>8耶和华的训词是正直的，能使人心快乐；耶和华的命令是清洁的，能使人的眼睛明亮。9耶和华的话语“耶和华的话语”原文作“耶和华的敬畏”是洁净的，能坚立到永远；耶和华的典章是真实的，完全公义；10都比金子宝贵，比大量的精金更宝贵；比蜜甘甜，比蜂房滴下来的蜜更甘甜；11并且你的仆人也借着这些得到警戒，谨守这些就得着大赏赐。</p>
</blockquote>
<h2 id="尾声"><a href="#尾声" class="headerlink" title="尾声"></a>尾声</h2><p>大卫，在诗歌的结尾讲了这样一段话：</p>
<blockquote>
<p>12谁能知道自己的错误呢？ 求你赦免我隐而未现的过失。 13求你拦阻你仆人，不犯任意妄为的罪， 不许它们辖制我；我才可以完全，不犯大过。<br>14耶和华我的盘石、我的救赎主啊！愿我口中的言语、心里的意念，都在你面前蒙悦纳。</p>
</blockquote>
<p>大卫，请求神原谅他所犯的罪，甚至是那些他自己没有意识到的罪恶。更进一步，他请求神可以帮助他不再犯罪。因为，当他意识到宇宙万物的精妙和神的话语的以后，他理所当然的选择了谦卑的求神能够悦纳他的心思意念，做他的磐石和救赎者。</p>
<p>多么美好啊？宇宙的创造者，做你我的磐石，你我的救赎者。</p>
<h2 id="我们"><a href="#我们" class="headerlink" title="我们"></a>我们</h2><p>我们应该如何做？</p>
<p>谦卑</p>
<p>思考</p>
<p>敬畏</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/05/yisaiya4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/05/yisaiya4/" class="post-title-link" itemprop="url">醒来吧！神的子民 51:9-52</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-05 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-05T00:00:00Z">2020-07-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bible/" itemprop="url" rel="index"><span itemprop="name">Bible</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/07/05/yisaiya4/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/07/05/yisaiya4/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="旅程"><a href="#旅程" class="headerlink" title="旅程"></a>旅程</h1><p>当我们即将踏上一段新的旅程，我们会准备行囊，心情激动。但是，如果旅程迟迟推迟，我们很可能就会渐渐失去激动的心情，然后把行囊中的种种拿出来。我们可能重新整理床铺，渐渐忘记即将发生的旅程。</p>
<h1 id="基督徒的旅程"><a href="#基督徒的旅程" class="headerlink" title="基督徒的旅程"></a>基督徒的旅程</h1><h2 id="醒来吧，耶和华的臂膀-51-9-16"><a href="#醒来吧，耶和华的臂膀-51-9-16" class="headerlink" title="醒来吧，耶和华的臂膀!(51:9-16)"></a>醒来吧，耶和华的臂膀!(51:9-16)</h2><blockquote>
<p>耶和华的膀臂啊，醒来吧!醒来吧!穿上能力吧!像古时的日子，像上古的世代一样醒来吧! 从前砍碎了拉哈伯， 刺透了海龙的，不是你吗?</p>
</blockquote>
<p>以色列人终于开始重新呼唤神的帮助，就像当年带以色列出埃及一样，拯救他们。以色列人终于意识到神的能力。</p>
<p>可是</p>
<p>该清醒的不是神，而是以色列人。</p>
<h2 id="醒来吧，耶路撒冷，从醉-罪-中醒来-51-17-23"><a href="#醒来吧，耶路撒冷，从醉-罪-中醒来-51-17-23" class="headerlink" title="醒来吧，耶路撒冷，从醉(罪)中醒来!(51:17-23)"></a>醒来吧，耶路撒冷，从醉(罪)中醒来!(51:17-23)</h2><blockquote>
<p>17耶路撒冷啊，醒来!醒来!站起来吧! 你从耶和华的手中喝了他烈怒的杯， 喝尽了那使人摇摇摆摆的爵。</p>
</blockquote>
<p>以色列人才是应该从醉酒中醒来。他们面临的痛苦都是因为他们喝了耶和华愤怒的杯。正是因为以色列人犯罪，才收到神公义的审判。</p>
<p>但是，神，决定拿走那愤怒的杯，救赎以色列。（为什么呢？）</p>
<p>以色列的仇敌将会承担愤怒的杯。（为什么呢？）</p>
<h2 id="醒来吧，锡安，换衣服准备离开-52-1-12"><a href="#醒来吧，锡安，换衣服准备离开-52-1-12" class="headerlink" title="醒来吧，锡安，换衣服准备离开!(52:1-12)"></a>醒来吧，锡安，换衣服准备离开!(52:1-12)</h2><blockquote>
<p>1 锡安哪!你要醒来; 醒来，披上你的力量。 圣城耶路撒冷啊! 要穿上你华美的衣服。 因为未受割礼的和不洁净的人， 都再不得进到你那里去。2 耶路撒冷啊!抖下尘土， 起来，坐在位上吧! 锡安被掳的居民哪! 解开你颈项上的锁炼。</p>
</blockquote>
<p>耶和华与神的子民住在一起了，耶路撒冷将会成为真正的圣城。这也正是福音的预言。</p>
<p>要离开，不要触摸不洁净的东西。不要留恋即将毁灭的世界了，因为我们将要去的是圣洁的地方。而且，神会保守：</p>
<blockquote>
<p>11 你们要离开，要离开，要从那里出来， 我没有对雅各的后裔说过: 不要触摸不洁净的东西。扛抬耶和华器皿的啊! 我耶和华讲说公义， 你们要从巴比伦城中出来，要自洁。 12 你们出来，不必着急; 以色列的 神必作你们的后盾。向不能拯救人的神祈求的，</p>
</blockquote>
<p>基督徒处在同样的世代，救赎的世代，离开巴比伦的世代，我们应该做好准备离开的世代。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/28/timotai2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lambda.jpeg">
      <meta itemprop="name" content="Zhe">
      <meta itemprop="description" content="Things are correlated">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhe">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/28/timotai2/" class="post-title-link" itemprop="url">传道人的传承：提摩太后书</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-28 00:00:00" itemprop="dateCreated datePublished" datetime="2020-06-28T00:00:00Z">2020-06-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bible/" itemprop="url" rel="index"><span itemprop="name">Bible</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/06/28/timotai2/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/06/28/timotai2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="传道人的传承"><a href="#传道人的传承" class="headerlink" title="传道人的传承"></a>传道人的传承</h1><blockquote>
<p>我在上帝面前，并在将来审判活人死人的基督耶稣面前，凭着他的显现和他的国度郑重地劝戒你：<br>2务要传道；无论得时不得时总要专心，并以百般的忍耐和各样的教导责备人，警戒人，劝勉人。<br>3因为时候将到，那时人会厌烦健全的教导，耳朵发痒，就随心所欲地增添好些教师，<br>4并且掩耳不听真理，偏向无稽的传说。<br>5至于你，凡事要谨慎，忍受苦难，做传福音的工作，尽你的职分。<br>6至于我，我已经被浇献，离世的时候到了。<br>7那美好的仗我已经打过了，当跑的路我已经跑尽了，该信的道我已经守住了。<br>8从此以后，有公义的冠冕为我存留，就是按着公义审判的主到了那日要赐给我的；不但赐给我，也赐给凡爱慕他显现的人。<br>《提摩太后书》4</p>
</blockquote>
<p>这封书信是身在牢狱中的保罗写给新一代传道人提摩太的，从信中我们也可以看到，保罗已经走到了生命的尽头。他留下了那句经典的经文，每一个传道人都铭记在心：</p>
<blockquote>
<p>7那美好的仗我已经打过了，当跑的路我已经跑尽了，该信的道我已经守住了。<br>8从此以后，有公义的冠冕为我存留，就是按着公义审判的主到了那日要赐给我的；不但赐给我，也赐给凡爱慕他显现的人。</p>
</blockquote>
<p>保罗当时身陷囹圄，教会内部开始出现离弃真道的人，背弃信仰，否认复活的事情。更加可怕的是，教会出现了很多假教师，他们不讲真理，却说虚妄的话，教导别人离弃信仰。他心急如焚。</p>
<p>而提摩太一直都是保罗信任的同工，他从小从祖母哪里接受了旧约圣经的教导，作为教会新一代的代领人，他面临很多挑战：人们背弃信仰，教会中假教师横行。</p>
<p>正是再这样的情况下，第一代传道人代表：保罗，写信给新一代传道人：提摩太，提醒他一定要持守真理，传讲福音。保罗为提摩太指明了道路：</p>
<blockquote>
<p>16 圣经都是上帝所默示的“圣经都是上帝所默示的”或译“凡上帝所默示的圣经”。于教训、督责、使人归正、教导人学义都是有益的，<br>17 叫属上帝的人得以完全，预备行各样的善事。</p>
</blockquote>
<p>他希望提摩太可以持守这圣经完备的教导，即使面对苦难，也可以坚持下去，并且将耶稣基督的福音传讲出去。</p>
<p>这就是一个老传道人对新传道人最后的叮嘱。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhe"
      src="/images/lambda.jpeg">
  <p class="site-author-name" itemprop="name">Zhe</p>
  <div class="site-description" itemprop="description">Things are correlated</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wangzhe3224" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wangzhe3224" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangzhetju@gmail.com" title="E-Mail → mailto:wangzhetju@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.co.uk/citations?hl=en&user=6yOk010AAAAJ" title="Google → https:&#x2F;&#x2F;scholar.google.co.uk&#x2F;citations?hl&#x3D;en&amp;user&#x3D;6yOk010AAAAJ" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/wangzhetju" title="StackOverflow → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;wangzhetju" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhe</span>
</div>

<span id="timeDate">Loding time...</span><span id="times">...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("01/01/2020 00:00:00");//在此处修改你的建站时间，格式：月/日/年 时:分:秒
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "Running for "+dnum+" Days "; 
        document.getElementById("times").innerHTML = hnum + " Hour " + mnum + " Min " + snum + " Secs"; 
    } 
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      script.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://wangzhe.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>

    </div>
</body>
</html>
